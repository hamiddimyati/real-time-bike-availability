{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.mllib.tree.DecisionTree\n",
    "import org.apache.spark.mllib.regression.LabeledPoint\n",
    "import org.apache.spark.mllib.linalg.Vectors\n",
    "import org.apache.spark.mllib.tree.configuration.Algo._\n",
    "import org.apache.spark.mllib.tree.impurity.Variance\n",
    "import org.apache.spark.ml.regression.{RandomForestRegressionModel, RandomForestRegressor}\n",
    "import org.apache.spark.sql.Encoders\n",
    "import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@5634bf81\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@5634bf81"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder.master(\"local[*]\").appName(\"SparkML\").getOrCreate()\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path = /home/florent/id2221_project/data/outputs/dataset/2019-09.csv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/florent/id2221_project/data/outputs/dataset/2019-09.csv"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path = \"/home/florent/id2221_project/data/outputs/dataset/2019-09.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataRDD = MapPartitionsRDD[2] at filter at <console>:49\n",
       "header = x_coo,y_coo,z_coo,year,month,day,hour,min,nb_bikes_available\n",
       "dataRDD = MapPartitionsRDD[2] at filter at <console>:49\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[2] at filter at <console>:49"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Load and parse the data file.\n",
    "\n",
    "var dataRDD = sc.textFile(path)\n",
    "val header = dataRDD.first()\n",
    "dataRDD = dataRDD.filter(row => row != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parsedData = MapPartitionsRDD[3] at map at <console>:43\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[3] at map at <console>:43"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val parsedData = dataRDD.map { line =>\n",
    "    val parts = line.split(\",\").map(_.toDouble)\n",
    "    LabeledPoint(parts.last, Vectors.dense(parts.init))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((31.0,[0.4909949444970359,-0.4513649771070291,0.7451131604793488,2019.0,9.0,1.0,0.0,0.0]), (30.0,[0.4909949444970359,-0.4513649771070291,0.7451131604793488,2019.0,9.0,1.0,0.0,41.0]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsedData.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://spark.apache.org/docs/1.0.2/mllib-decision-tree.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maxDepth = 5\n",
       "model = DecisionTreeModel regressor of depth 5 with 63 nodes\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeModel regressor of depth 5 with 63 nodes"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val maxDepth = 5\n",
    "val model = DecisionTree.train(parsedData,\n",
    "                               Regression,\n",
    "                               Variance,\n",
    "                               maxDepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "valuesAndPreds = MapPartitionsRDD[28] at map at <console>:45\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[28] at map at <console>:45"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val valuesAndPreds = parsedData.map { point =>\n",
    "    val prediction = model.predict(point.features)\n",
    "    (point.label, prediction)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Mean Squared Error = 28328.85010637164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MSE = 28328.85010637164\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "28328.85010637164"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val MSE = valuesAndPreds.map{ case(v, p) => math.pow((v - p), 2)}.mean()\n",
    "println(\"training Mean Squared Error = \" + MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(sc, \"./decision_tree.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Record\n",
       "schema = StructType(StructField(x_coo,DoubleType,false), StructField(y_coo,DoubleType,false), StructField(z_coo,DoubleType,false), StructField(year,IntegerType,false), StructField(month,IntegerType,false), StructField(day,IntegerType,false), StructField(hour,IntegerType,false), StructField(min,IntegerType,false), StructField(nb_bikes_available,IntegerType,false))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(x_coo,DoubleType,false), StructField(y_coo,DoubleType,false), StructField(z_coo,DoubleType,false), StructField(year,IntegerType,false), StructField(month,IntegerType,false), StructField(day,IntegerType,false), StructField(hour,IntegerType,false), StructField(min,IntegerType,false), StructField(nb_bikes_available,IntegerType,false))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class Record(x_coo: Double,y_coo: Double, z_coo: Double, year: Int, month: Int, day: Int, hour: Int, min: Int, nb_bikes_available: Int)\n",
    "val schema = Encoders.product[Record].schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data = [x_coo: double, y_coo: double ... 7 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[x_coo: double, y_coo: double ... 7 more fields]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = spark.read\n",
    "                .option(\"header\", \"true\")\n",
    "                .schema(schema)\n",
    "                .csv(path)\n",
    "                .as[Record]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+------------------+----+-----+---+----+---+------------------+\n",
      "|             x_coo|              y_coo|             z_coo|year|month|day|hour|min|nb_bikes_available|\n",
      "+------------------+-------------------+------------------+----+-----+---+----+---+------------------+\n",
      "|0.4909949444970359|-0.4513649771070291|0.7451131604793488|2019|    9|  1|   0|  0|                31|\n",
      "|0.4909949444970359|-0.4513649771070291|0.7451131604793488|2019|    9|  1|   0| 41|                30|\n",
      "|0.4909949444970359|-0.4513649771070291|0.7451131604793488|2019|    9|  1|   0| 59|                31|\n",
      "|0.4909949444970359|-0.4513649771070291|0.7451131604793488|2019|    9|  1|   1|  5|                30|\n",
      "|0.4909949444970359|-0.4513649771070291|0.7451131604793488|2019|    9|  1|   1| 15|                31|\n",
      "|0.4909949444970359|-0.4513649771070291|0.7451131604793488|2019|    9|  1|   2| 13|                30|\n",
      "|0.4909949444970359|-0.4513649771070291|0.7451131604793488|2019|    9|  1|   2| 13|                29|\n",
      "|0.4909949444970359|-0.4513649771070291|0.7451131604793488|2019|    9|  1|   2| 36|                30|\n",
      "|0.4909949444970359|-0.4513649771070291|0.7451131604793488|2019|    9|  1|   2| 48|                29|\n",
      "|0.4909949444970359|-0.4513649771070291|0.7451131604793488|2019|    9|  1|   2| 55|                28|\n",
      "+------------------+-------------------+------------------+----+-----+---+----+---+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x_coo: double (nullable = true)\n",
      " |-- y_coo: double (nullable = true)\n",
      " |-- z_coo: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- min: integer (nullable = true)\n",
      " |-- nb_bikes_available: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cols = Array(x_coo, y_coo, z_coo, year, month, day, hour, min)\n",
       "assembler = vecAssembler_55260010e253\n",
       "featureDf = [x_coo: double, y_coo: double ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[x_coo: double, y_coo: double ... 8 more fields]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cols = Array(\"x_coo\", \"y_coo\", \"z_coo\", \"year\", \"month\", \"day\", \"hour\", \"min\")\n",
    "\n",
    "// VectorAssembler to add feature column\n",
    "// input columns - cols\n",
    "// feature column - features\n",
    "val assembler = new VectorAssembler().setInputCols(cols)\n",
    "                                     .setOutputCol(\"features\")\n",
    "\n",
    "val featureDf = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x_coo: double (nullable = true)\n",
      " |-- y_coo: double (nullable = true)\n",
      " |-- z_coo: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- min: integer (nullable = true)\n",
      " |-- nb_bikes_available: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featureDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indexer = strIdx_58df42cb4a8b\n",
       "labelDf = [x_coo: double, y_coo: double ... 9 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[x_coo: double, y_coo: double ... 9 more fields]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val indexer = new StringIndexer().setInputCol(\"nb_bikes_available\")\n",
    "                                 .setOutputCol(\"label\")\n",
    "\n",
    "val labelDf = indexer.fit(featureDf).transform(featureDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x_coo: double (nullable = true)\n",
      " |-- y_coo: double (nullable = true)\n",
      " |-- z_coo: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- min: integer (nullable = true)\n",
      " |-- nb_bikes_available: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seed = 5043\n",
       "trainingData = [x_coo: double, y_coo: double ... 9 more fields]\n",
       "testData = [x_coo: double, y_coo: double ... 9 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[x_coo: double, y_coo: double ... 9 more fields]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val seed = 5043\n",
    "val Array(trainingData, testData) = labelDf.randomSplit(Array(0.7, 0.3), seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rf = rfr_74796955c5ef\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "rfr_74796955c5ef"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rf = new RandomForestRegressor().setLabelCol(\"label\")\n",
    "                                    .setFeaturesCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rfModel = RandomForestRegressionModel (uid=rfr_74796955c5ef) with 20 trees\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressionModel (uid=rfr_74796955c5ef) with 20 trees"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rfModel = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+--------------------+\n",
      "|       prediction|label|            features|\n",
      "+-----------------+-----+--------------------+\n",
      "|100.2909265923264|  3.0|[-0.1145248311126...|\n",
      "|100.2909265923264| 10.0|[-0.1145248311126...|\n",
      "|100.2909265923264| 11.0|[-0.1145248311126...|\n",
      "|100.2909265923264|  9.0|[-0.1145248311126...|\n",
      "|100.2909265923264| 36.0|[-0.1145248311126...|\n",
      "+-----------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictions = [x_coo: double, y_coo: double ... 10 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[x_coo: double, y_coo: double ... 10 more fields]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictions = rfModel.transform(testData)\n",
    "\n",
    "// Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling (hamid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.regression.{LinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor}\n",
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit, CrossValidator}\n",
    "import org.apache.spark.ml.feature.{VectorAssembler, MinMaxScaler, StandardScaler}\n",
    "import org.apache.spark.mllib.evaluation.RegressionMetrics\n",
    "import org.apache.spark.mllib.tree.RandomForest\n",
    "//import ml.dmlc.xgboost4j.scala.spark.{XGBoostRegressionModel, XGBoostRegressor}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case class Record(latitude: Double,longitude: Double, year: Int, month: Int, day: Int, hour: Int, min: Int, nb_bikes_available: Int)\n",
    "val schema = Encoders.product[Record].schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val data = spark.read\n",
    "                .option(\"header\", \"true\")\n",
    "                .schema(schema)\n",
    "                .csv(path)\n",
    "                .as[Record]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val seed = 5043\n",
    "val Array(trainingData, testData) = data.randomSplit(Array(0.7, 0.3), seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val cols = Array(\"latitude\", \"longitude\", \"year\", \"month\", \"day\", \"hour\", \"min\")\n",
    "\n",
    "// VectorAssembler to add feature column\n",
    "// input columns - cols\n",
    "// feature column - features\n",
    "val assembler = new VectorAssembler().setInputCols(cols)\n",
    "                                     .setOutputCol(\"features\")\n",
    "\n",
    "//val featureDf = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val indexer = new StringIndexer().setInputCol(\"nb_bikes_available\")\n",
    "                                 .setOutputCol(\"label\")\n",
    "\n",
    "//val labelDf = indexer.fit(featureDf).transform(featureDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val scaler = new StandardScaler()\n",
    "                 .setInputCol(\"features\")\n",
    "                 .setOutputCol(\"scaledFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val model = new RandomForestRegressor()\n",
    "                .setLabelCol(\"label\")\n",
    "                .setFeaturesCol(\"scaledFeatures\")\n",
    "                .setNumTrees(25)\n",
    "                .setMaxDepth(10)\n",
    "                .setMaxBins(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val pipeline = new Pipeline()\n",
    "                .setStages(Array(assembler, indexer, scaler, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val model = pipeline.fit(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val RFPrediction = model.transform(testingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFPrediction.select(\"prediction\", \"label\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//.setNumTrees(25)\n",
    "//.setMaxDepth(10)\n",
    "//.setMaxBins(25)\n",
    "val evaluator = new RegressionEvaluator()\n",
    "                    .setLabelCol(\"label\")\n",
    "                    .setPredictionCol(\"prediction\")\n",
    "                    .setMetricName(\"rmse\")\n",
    "val rmse = evaluator.evaluate(RFPrediction)\n",
    "println(s\"RMSE = $rmse\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
